{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2_S5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaLEOsv5n_YT"
      },
      "source": [
        "Importing the required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_Bc28xxoXUv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAePrSEIoFJu"
      },
      "source": [
        "Uploading the Stanford dataset and extracting the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9PIXxj4jKzT",
        "outputId": "fdae8e9e-f200-4976-8aa2-f87be1c40073"
      },
      "source": [
        "dataset_sentences = pd.read_csv('/content/datasetSentences.txt', sep='\\t')\n",
        "print(dataset_sentences.shape, '\\n', dataset_sentences.head())\n",
        "\n",
        "sentiment_labels = pd.read_csv('/content/sentiment_labels.txt', sep='|')                \n",
        "sentiment_labels = sentiment_labels.rename(columns={'phrase ids': 'phrase_id', \n",
        "                                                    'sentiment values': 'sentiment_value'})\n",
        "print(sentiment_labels.shape, '\\n', sentiment_labels.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11855, 2) \n",
            "    sentence_index                                           sentence\n",
            "0               1  The Rock is destined to be the 21st Century 's...\n",
            "1               2  The gorgeously elaborate continuation of `` Th...\n",
            "2               3                     Effective but too-tepid biopic\n",
            "3               4  If you sometimes like to go to the movies to h...\n",
            "4               5  Emerges as something rare , an issue movie tha...\n",
            "(239232, 2) \n",
            "    phrase_id  sentiment_value\n",
            "0          0          0.50000\n",
            "1          1          0.50000\n",
            "2          2          0.44444\n",
            "3          3          0.50000\n",
            "4          4          0.42708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoNN2jy9pNCJ"
      },
      "source": [
        "Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWa_vZZkp2JP"
      },
      "source": [
        "sentence_sentiment = dataset_sentences\n",
        "phrase_sentiment = dict(zip(list(sentiment_labels.phrase_id), \n",
        "                            list(sentiment_labels.sentiment_value)))\n",
        "\n",
        "\n",
        "with open('/content/STree.txt') as file:\n",
        "    stree = file.readlines()\n",
        "stree = [line.strip().split('|') for line in stree] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsskfx23pD5s"
      },
      "source": [
        "Phrase to Sentence mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "yHSM4UpykJV8",
        "outputId": "500374c8-0aef-4af6-d806-06bccff3741b"
      },
      "source": [
        "from statistics import mean\n",
        "\n",
        "# average sentiments per sentence (otherwise long sentences get high sentiments)\n",
        "sentiments = [mean(phrase_sentiment[int(phrase_id)] for phrase_id in phrase_ids) \n",
        "              for phrase_ids in stree]\n",
        "# define neutral sentiment as values within [0.5, 0.55) \n",
        "sentiments = [2 if sentiment >= 0.5 and sentiment < 0.55 else sentiment \n",
        "              for sentiment in sentiments]\n",
        "# all negative sentiment values to 0, all positive sentiment values to 1\n",
        "sentiments = [int(round(sentiment)) \n",
        "              for sentiment in sentiments]\n",
        "# concatenate sentence sentiment values with corresponding sentence texts\n",
        "sentence_sentiment['sentiment_value'] = sentiments\n",
        "\n",
        "sentence_sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11850</th>\n",
              "      <td>11851</td>\n",
              "      <td>A real snooze .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11851</th>\n",
              "      <td>11852</td>\n",
              "      <td>No surprises .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11852</th>\n",
              "      <td>11853</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11853</th>\n",
              "      <td>11854</td>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11854</th>\n",
              "      <td>11855</td>\n",
              "      <td>In this case zero .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11855 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index  ... sentiment_value\n",
              "0                   1  ...               0\n",
              "1                   2  ...               0\n",
              "2                   3  ...               0\n",
              "3                   4  ...               0\n",
              "4                   5  ...               0\n",
              "...               ...  ...             ...\n",
              "11850           11851  ...               0\n",
              "11851           11852  ...               0\n",
              "11852           11853  ...               0\n",
              "11853           11854  ...               0\n",
              "11854           11855  ...               0\n",
              "\n",
              "[11855 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwzRjwF3JRJX"
      },
      "source": [
        "sentence_sentiment = sentence_sentiment.rename(columns={'sentence': 'tweets', 'sentiment_value': 'labels'})\n",
        "sentence_sentiment = sentence_sentiment[['tweets', 'labels']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "OHoyzJ6yJYDS",
        "outputId": "b13c2d3e-c61b-4df0-d84d-6a188fe3a9d1"
      },
      "source": [
        "sentence_sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11850</th>\n",
              "      <td>A real snooze .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11851</th>\n",
              "      <td>No surprises .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11852</th>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11853</th>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11854</th>\n",
              "      <td>In this case zero .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11855 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweets  labels\n",
              "0      The Rock is destined to be the 21st Century 's...       0\n",
              "1      The gorgeously elaborate continuation of `` Th...       0\n",
              "2                         Effective but too-tepid biopic       0\n",
              "3      If you sometimes like to go to the movies to h...       0\n",
              "4      Emerges as something rare , an issue movie tha...       0\n",
              "...                                                  ...     ...\n",
              "11850                                    A real snooze .       0\n",
              "11851                                     No surprises .       0\n",
              "11852  We 've seen the hippie-turned-yuppie plot befo...       0\n",
              "11853  Her fans walked out muttering words like `` ho...       0\n",
              "11854                                In this case zero .       0\n",
              "\n",
              "[11855 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baP89VYSkhu6",
        "outputId": "f678f517-a5bd-4ed5-ed30-440296e8b9f5"
      },
      "source": [
        "SEED = 1234\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb3967e6ab0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwBh6ORNpY8r"
      },
      "source": [
        "Defining Tweet & Label fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "holpvXwfJchU"
      },
      "source": [
        "Tweet = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-i_szGKKt-h"
      },
      "source": [
        "fields = [('tweets', Tweet),('labels',Label)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3pjfFuaKxf7"
      },
      "source": [
        "#example = [torchtext.legacy.data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])]\n",
        "example = [torchtext.legacy.data.Example.fromlist([sentence_sentiment.tweets[i],sentence_sentiment.labels[i]], fields) for i in range(sentence_sentiment.shape[0])]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zJJgl9ym0Tq"
      },
      "source": [
        "stanfordDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqxh02qIpd1E"
      },
      "source": [
        "Data split for train, test & validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c06D4xIhT3al"
      },
      "source": [
        "(train, valid, test) = stanfordDataset.split(split_ratio=[70, 15, 15], random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAk0vp4EoTSm",
        "outputId": "31754cae-0efb-44d3-f159-44fae7ec6a8b"
      },
      "source": [
        "(len(train), len(valid), len(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8298, 1779, 1778)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9cOiTzaK7vl",
        "outputId": "5006782f-8696-4f04-fb7b-df86f04c091c"
      },
      "source": [
        "vars(train.examples[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 0,\n",
              " 'tweets': ['Not',\n",
              "  'only',\n",
              "  'are',\n",
              "  'the',\n",
              "  'film',\n",
              "  \"'s\",\n",
              "  'Sopranos',\n",
              "  'gags',\n",
              "  'incredibly',\n",
              "  'dated',\n",
              "  'and',\n",
              "  'unfunny',\n",
              "  ',',\n",
              "  'they',\n",
              "  'also',\n",
              "  'demonstrate',\n",
              "  'how',\n",
              "  'desperate',\n",
              "  'the',\n",
              "  'makers',\n",
              "  'of',\n",
              "  'this',\n",
              "  '`',\n",
              "  'we',\n",
              "  \"'re\",\n",
              "  '-',\n",
              "  'doing',\n",
              "  '-',\n",
              "  'it',\n",
              "  '-',\n",
              "  'for',\n",
              "  '-',\n",
              "  'the',\n",
              "  '-',\n",
              "  'cash',\n",
              "  \"'\",\n",
              "  'sequel',\n",
              "  'were',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z5cwbsDpoLJ"
      },
      "source": [
        "Vocabulary build-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNtIBFdD3yCz"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3gyf_obN1OA",
        "outputId": "8f48e8b1-076b-4e84-d0c9-618658bc2c6b"
      },
      "source": [
        "!pip install googletrans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.7/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2020.12.22)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2020.12.5)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (1.2.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHsh5yvEQGt7"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36APxxz5ozVa",
        "outputId": "f991c783-8f63-450b-a6f2-a729591d5bf1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWzOg2z8OOPu"
      },
      "source": [
        "import googletrans\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzuJ0IUEptKV"
      },
      "source": [
        "Data Augmentation using back_translate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKP_Joe2shGG"
      },
      "source": [
        "def back_translate(sentence, p=0.1):\n",
        "  if random.uniform(0,1) > p:\n",
        "    return sentence\n",
        "\n",
        "  # combine tokenized sentence into one string\n",
        "  sentence = ' '.join(sentence)\n",
        "\n",
        "  # instantiate translator\n",
        "  translator = googletrans.Translator()\n",
        "\n",
        "  # choose a target language\n",
        "  available_langs = list(googletrans.LANGUAGES.keys())\n",
        "  trans_lang = random.choice(available_langs)\n",
        "\n",
        "  # translate to the target language\n",
        "  translations = translator.translate(sentence, lang_tgt=trans_lang) \n",
        "  #print(translations)\n",
        "\n",
        "  # translate back to original language\n",
        "  translations_en_random = translator.translate(translations, lang_src=trans_lang, lang_tgt='en') \n",
        "  #print(translations_en_random)\n",
        "\n",
        "  # select only one translation\n",
        "  if len(translations_en_random) > 1:\n",
        "    translations_en_random = translations_en_random[0]\n",
        "\n",
        "  return word_tokenize(translations_en_random)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gBaGx18p0C7"
      },
      "source": [
        "Data Augmentation using random_deletion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOiasvY3QeQ0"
      },
      "source": [
        "def random_deletion(sentence, p=0.5): \n",
        "    # return if single word\n",
        "    if len(sentence) == 1: \n",
        "        return sentence\n",
        "    # delete words\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p, sentence)) \n",
        "    # if nothing left, sample a random word\n",
        "    if len(remaining) == 0: \n",
        "        return [random.choice(sentence)] \n",
        "    else:\n",
        "        return remaining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUXks5RHp33Y"
      },
      "source": [
        "Data Augmentation using random_swap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXXkz6DxSACp"
      },
      "source": [
        "def random_swap(sentence, n=5): \n",
        "    if len(sentence) < 2:\n",
        "      return sentence\n",
        "    length = range(len(sentence)) \n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(length, 2)\n",
        "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUBgUWqtSiar"
      },
      "source": [
        "for example in train.examples:\n",
        "    #example.tweets = back_translate(example.tweets, p=0.1)\n",
        "    example.tweets = random_deletion(example.tweets, p=0.5)\n",
        "    example.tweets = random_swap(example.tweets, n=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mZvLFIPSlxN"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "Tweet.build_vocab(train, max_size = MAX_VOCAB_SIZE)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73GJh3FEQokT",
        "outputId": "c2b8b623-a9a4-4da2-b9d8-8baeb82d726f"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  12015\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('.', 3918), (',', 3444), ('the', 3034), ('and', 2198), ('of', 2156), ('a', 2088), ('to', 1523), ('-', 1406), ('is', 1239), (\"'s\", 1221)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsa8xOoHV1P-"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqBN3_Og0b4A"
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits((train, valid, test), batch_size = 16, \n",
        "                                                            sort_key = lambda x: len(x.tweets),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNOsAgM33T0d",
        "outputId": "2190713a-4a6f-4620-845a-30d5149ebe17"
      },
      "source": [
        "next(iter(train_iterator))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.legacy.data.batch.Batch of size 16]\n",
              "\t[.tweets]:('[torch.LongTensor of size 16x17]', '[torch.LongTensor of size 16]')\n",
              "\t[.labels]:[torch.LongTensor of size 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prCDX2BqWNw-"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39dGkMp0qBOz"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orR3AXPeWQjG"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, \n",
        "                 n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                               hidden_dim, \n",
        "                               num_layers=n_layers, \n",
        "                               dropout=dropout,\n",
        "                               batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function (softmax)\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aD5xaUeqDir"
      },
      "source": [
        "Hyper-Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4oCxJr1WcKK",
        "outputId": "d64e3e96-7cda-4678-8bd6-cf9e8584add3"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(12015, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10BHE8ki05Gk",
        "outputId": "703f1491-1cb6-4c87-e195-d0058c05cc26"
      },
      "source": [
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,846,403 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSwV3u8a06U9"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYuOgrxGqL2-"
      },
      "source": [
        "Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clCpxFL71CBy"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweets   \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.labels)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvRVGngqqOh6"
      },
      "source": [
        "Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75EzJ8cE1FWr"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweets\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJjd_2FmqQ_3"
      },
      "source": [
        "Run the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0DIkR_A1JS-",
        "outputId": "79989e1d-150a-4ce7-e9b7-4667271c25d3"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.981 | Train Acc: 55.17%\n",
            "\t Val. Loss: 0.948 |  Val. Acc: 55.69% \n",
            "\n",
            "\tTrain Loss: 0.867 | Train Acc: 67.57%\n",
            "\t Val. Loss: 0.960 |  Val. Acc: 57.76% \n",
            "\n",
            "\tTrain Loss: 0.823 | Train Acc: 72.83%\n",
            "\t Val. Loss: 0.978 |  Val. Acc: 56.47% \n",
            "\n",
            "\tTrain Loss: 0.797 | Train Acc: 75.24%\n",
            "\t Val. Loss: 0.989 |  Val. Acc: 54.91% \n",
            "\n",
            "\tTrain Loss: 0.779 | Train Acc: 77.32%\n",
            "\t Val. Loss: 0.949 |  Val. Acc: 59.43% \n",
            "\n",
            "\tTrain Loss: 0.765 | Train Acc: 79.08%\n",
            "\t Val. Loss: 0.948 |  Val. Acc: 59.65% \n",
            "\n",
            "\tTrain Loss: 0.753 | Train Acc: 80.08%\n",
            "\t Val. Loss: 0.945 |  Val. Acc: 60.10% \n",
            "\n",
            "\tTrain Loss: 0.743 | Train Acc: 81.39%\n",
            "\t Val. Loss: 0.958 |  Val. Acc: 58.82% \n",
            "\n",
            "\tTrain Loss: 0.736 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.964 |  Val. Acc: 58.31% \n",
            "\n",
            "\tTrain Loss: 0.730 | Train Acc: 82.84%\n",
            "\t Val. Loss: 0.954 |  Val. Acc: 59.65% \n",
            "\n",
            "\tTrain Loss: 0.723 | Train Acc: 83.45%\n",
            "\t Val. Loss: 0.948 |  Val. Acc: 59.99% \n",
            "\n",
            "\tTrain Loss: 0.719 | Train Acc: 83.68%\n",
            "\t Val. Loss: 0.957 |  Val. Acc: 59.21% \n",
            "\n",
            "\tTrain Loss: 0.715 | Train Acc: 83.95%\n",
            "\t Val. Loss: 0.953 |  Val. Acc: 59.15% \n",
            "\n",
            "\tTrain Loss: 0.713 | Train Acc: 84.26%\n",
            "\t Val. Loss: 0.958 |  Val. Acc: 59.10% \n",
            "\n",
            "\tTrain Loss: 0.709 | Train Acc: 84.44%\n",
            "\t Val. Loss: 0.953 |  Val. Acc: 59.43% \n",
            "\n",
            "\tTrain Loss: 0.706 | Train Acc: 84.78%\n",
            "\t Val. Loss: 0.962 |  Val. Acc: 58.59% \n",
            "\n",
            "\tTrain Loss: 0.703 | Train Acc: 85.01%\n",
            "\t Val. Loss: 0.961 |  Val. Acc: 58.59% \n",
            "\n",
            "\tTrain Loss: 0.701 | Train Acc: 85.22%\n",
            "\t Val. Loss: 0.954 |  Val. Acc: 59.21% \n",
            "\n",
            "\tTrain Loss: 0.699 | Train Acc: 85.38%\n",
            "\t Val. Loss: 0.969 |  Val. Acc: 57.81% \n",
            "\n",
            "\tTrain Loss: 0.697 | Train Acc: 85.53%\n",
            "\t Val. Loss: 0.944 |  Val. Acc: 60.55% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2AUBu-88QP9",
        "outputId": "7fe4052c-27f3-46c6-9d8b-0223d3008117"
      },
      "source": [
        "model.load_state_dict(torch.load('saved_weights.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.972 | Test Acc: 57.65%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R6Qj9eJ8UWd"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQN9AbRdqclI"
      },
      "source": [
        "User Input Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t8OHs_1P8bOP",
        "outputId": "2bc8a1e7-69db-4915-e588-6f33c99107cd"
      },
      "source": [
        "classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WuIkgkW48grs",
        "outputId": "c7cd2cc6-42cd-465f-c16f-32ae17b87540"
      },
      "source": [
        "classify_tweet(\"In his teen years, Obama has been known to use marijuana and cocaine.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    }
  ]
}