{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2_S7_Part1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaLEOsv5n_YT"
      },
      "source": [
        "Importing the required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_Bc28xxoXUv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAePrSEIoFJu"
      },
      "source": [
        "Uploading the Stanford dataset and extracting the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9PIXxj4jKzT",
        "outputId": "14c3a101-14ed-4b8c-b787-d6679ff1367d"
      },
      "source": [
        "dataset_sentences = pd.read_csv('/content/datasetSentences.txt', sep='\\t')\n",
        "print(dataset_sentences.shape, '\\n', dataset_sentences.head())\n",
        "\n",
        "sentiment_labels = pd.read_csv('/content/sentiment_labels.txt', sep='|')                \n",
        "sentiment_labels = sentiment_labels.rename(columns={'phrase ids': 'phrase_id', \n",
        "                                                    'sentiment values': 'sentiment_value'})\n",
        "print(sentiment_labels.shape, '\\n', sentiment_labels.head())"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11855, 2) \n",
            "    sentence_index                                           sentence\n",
            "0               1  The Rock is destined to be the 21st Century 's...\n",
            "1               2  The gorgeously elaborate continuation of `` Th...\n",
            "2               3                     Effective but too-tepid biopic\n",
            "3               4  If you sometimes like to go to the movies to h...\n",
            "4               5  Emerges as something rare , an issue movie tha...\n",
            "(239232, 2) \n",
            "    phrase_id  sentiment_value\n",
            "0          0          0.50000\n",
            "1          1          0.50000\n",
            "2          2          0.44444\n",
            "3          3          0.50000\n",
            "4          4          0.42708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoNN2jy9pNCJ"
      },
      "source": [
        "Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWa_vZZkp2JP"
      },
      "source": [
        "sentence_sentiment = dataset_sentences\n",
        "phrase_sentiment = dict(zip(list(sentiment_labels.phrase_id), \n",
        "                            list(sentiment_labels.sentiment_value)))\n",
        "\n",
        "\n",
        "with open('/content/STree.txt') as file:\n",
        "    stree = file.readlines()\n",
        "stree = [line.strip().split('|') for line in stree] "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsskfx23pD5s"
      },
      "source": [
        "Phrase to Sentence mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "yHSM4UpykJV8",
        "outputId": "892b14a0-2777-434a-eeff-720728d0751d"
      },
      "source": [
        "from statistics import mean\n",
        "\n",
        "# average sentiments per sentence (otherwise long sentences get high sentiments)\n",
        "sentiments = [mean(phrase_sentiment[int(phrase_id)] for phrase_id in phrase_ids) \n",
        "              for phrase_ids in stree]\n",
        "# define neutral sentiment as values within [0.5, 0.55) \n",
        "sentiments = [2 if sentiment >= 0.5 and sentiment < 0.55 else sentiment \n",
        "              for sentiment in sentiments]\n",
        "# all negative sentiment values to 0, all positive sentiment values to 1\n",
        "sentiments = [int(round(sentiment)) \n",
        "              for sentiment in sentiments]\n",
        "# concatenate sentence sentiment values with corresponding sentence texts\n",
        "sentence_sentiment['sentiment_value'] = sentiments\n",
        "\n",
        "sentence_sentiment"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11850</th>\n",
              "      <td>11851</td>\n",
              "      <td>A real snooze .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11851</th>\n",
              "      <td>11852</td>\n",
              "      <td>No surprises .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11852</th>\n",
              "      <td>11853</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11853</th>\n",
              "      <td>11854</td>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11854</th>\n",
              "      <td>11855</td>\n",
              "      <td>In this case zero .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11855 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index  ... sentiment_value\n",
              "0                   1  ...               0\n",
              "1                   2  ...               0\n",
              "2                   3  ...               0\n",
              "3                   4  ...               0\n",
              "4                   5  ...               0\n",
              "...               ...  ...             ...\n",
              "11850           11851  ...               0\n",
              "11851           11852  ...               0\n",
              "11852           11853  ...               0\n",
              "11853           11854  ...               0\n",
              "11854           11855  ...               0\n",
              "\n",
              "[11855 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwzRjwF3JRJX"
      },
      "source": [
        "sentence_sentiment = sentence_sentiment.rename(columns={'sentence': 'texts', 'sentiment_value': 'labels'})\n",
        "sentence_sentiment = sentence_sentiment[['texts', 'labels']]\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "OHoyzJ6yJYDS",
        "outputId": "a258e095-b4ae-41c5-a718-e710d3935c13"
      },
      "source": [
        "sentence_sentiment"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11850</th>\n",
              "      <td>A real snooze .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11851</th>\n",
              "      <td>No surprises .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11852</th>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11853</th>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11854</th>\n",
              "      <td>In this case zero .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11855 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texts  labels\n",
              "0      The Rock is destined to be the 21st Century 's...       0\n",
              "1      The gorgeously elaborate continuation of `` Th...       0\n",
              "2                         Effective but too-tepid biopic       0\n",
              "3      If you sometimes like to go to the movies to h...       0\n",
              "4      Emerges as something rare , an issue movie tha...       0\n",
              "...                                                  ...     ...\n",
              "11850                                    A real snooze .       0\n",
              "11851                                     No surprises .       0\n",
              "11852  We 've seen the hippie-turned-yuppie plot befo...       0\n",
              "11853  Her fans walked out muttering words like `` ho...       0\n",
              "11854                                In this case zero .       0\n",
              "\n",
              "[11855 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baP89VYSkhu6",
        "outputId": "ccc9c425-3c16-4221-bf1d-a3f60a899537"
      },
      "source": [
        "SEED = 1234\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff8f08d7910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwBh6ORNpY8r"
      },
      "source": [
        "Defining Text & Label fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "holpvXwfJchU"
      },
      "source": [
        "Text = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-i_szGKKt-h"
      },
      "source": [
        "fields = [('texts', Text),('labels',Label)]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3pjfFuaKxf7"
      },
      "source": [
        "#example = [torchtext.legacy.data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])]\n",
        "example = [torchtext.legacy.data.Example.fromlist([sentence_sentiment.texts[i],sentence_sentiment.labels[i]], fields) for i in range(sentence_sentiment.shape[0])]\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zJJgl9ym0Tq"
      },
      "source": [
        "stanfordDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c06D4xIhT3al"
      },
      "source": [
        "(train, test) = stanfordDataset.split(split_ratio=[70, 30], random_state = random.seed(SEED))"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1djUrRgTQqMr"
      },
      "source": [
        "Data split for train & test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAk0vp4EoTSm",
        "outputId": "61b27757-4d9b-47f6-a990-43ae499d04f2"
      },
      "source": [
        "(len(train), len(test))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8298, 3557)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9cOiTzaK7vl",
        "outputId": "579d537c-ceef-4ef6-aef8-7b68bf936545"
      },
      "source": [
        "vars(train.examples[10])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 0,\n",
              " 'texts': ['Not',\n",
              "  'only',\n",
              "  'are',\n",
              "  'the',\n",
              "  'film',\n",
              "  \"'s\",\n",
              "  'Sopranos',\n",
              "  'gags',\n",
              "  'incredibly',\n",
              "  'dated',\n",
              "  'and',\n",
              "  'unfunny',\n",
              "  ',',\n",
              "  'they',\n",
              "  'also',\n",
              "  'demonstrate',\n",
              "  'how',\n",
              "  'desperate',\n",
              "  'the',\n",
              "  'makers',\n",
              "  'of',\n",
              "  'this',\n",
              "  '`',\n",
              "  'we',\n",
              "  \"'re\",\n",
              "  '-',\n",
              "  'doing',\n",
              "  '-',\n",
              "  'it',\n",
              "  '-',\n",
              "  'for',\n",
              "  '-',\n",
              "  'the',\n",
              "  '-',\n",
              "  'cash',\n",
              "  \"'\",\n",
              "  'sequel',\n",
              "  'were',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z5cwbsDpoLJ"
      },
      "source": [
        "Vocabulary build-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNtIBFdD3yCz"
      },
      "source": [
        "Text.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHsh5yvEQGt7"
      },
      "source": [
        "import random"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mZvLFIPSlxN"
      },
      "source": [
        "MAX_VOCAB_SIZE = 12_000\n",
        "\n",
        "Text.build_vocab(train, max_size = MAX_VOCAB_SIZE)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73GJh3FEQokT",
        "outputId": "052b1cbc-0689-49fa-b0f4-da5479ce1e36"
      },
      "source": [
        "print('Size of input vocab : ', len(Text.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Text.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  12002\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('.', 7825), (',', 6898), ('the', 6012), ('and', 4411), ('of', 4380), ('a', 4214), ('to', 3009), ('-', 2740), (\"'s\", 2474), ('is', 2453)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsa8xOoHV1P-"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqBN3_Og0b4A"
      },
      "source": [
        "train_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits((train, test), batch_size = 16, \n",
        "                                                            sort_key = lambda x: len(x.texts),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNOsAgM33T0d",
        "outputId": "6bad666b-5f34-4bca-ab69-9cedd4b26e29"
      },
      "source": [
        "next(iter(train_iterator))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.legacy.data.batch.Batch of size 16]\n",
              "\t[.texts]:('[torch.LongTensor of size 16x10]', '[torch.LongTensor of size 16]')\n",
              "\t[.labels]:[torch.LongTensor of size 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prCDX2BqWNw-"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Text.vocab.stoi, tokens)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39dGkMp0qBOz"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orR3AXPeWQjG"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, \n",
        "                 n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                               hidden_dim, \n",
        "                               num_layers=n_layers, \n",
        "                               dropout=dropout,\n",
        "                               batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function (softmax)\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aD5xaUeqDir"
      },
      "source": [
        "Hyper-Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4oCxJr1WcKK",
        "outputId": "707a9aa1-2423-40c7-d493-4056a81a31a7"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Text.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(12002, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10BHE8ki05Gk",
        "outputId": "3630e345-f43d-417e-ccc1-7e47d937be8f"
      },
      "source": [
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,842,503 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSwV3u8a06U9"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYuOgrxGqL2-"
      },
      "source": [
        "Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clCpxFL71CBy"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.texts   \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.labels)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvRVGngqqOh6"
      },
      "source": [
        "Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75EzJ8cE1FWr"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.texts\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJjd_2FmqQ_3"
      },
      "source": [
        "Run the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0DIkR_A1JS-",
        "outputId": "ee948e45-b026-4f56-db75-d8bab9d87a24"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    # valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # # save the best model\n",
        "    # if valid_loss < best_valid_loss:\n",
        "    #     best_valid_loss = valid_loss\n",
        "    #     torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    #print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.992 | Train Acc: 56.31%\n",
            "\tTrain Loss: 0.925 | Train Acc: 61.69%\n",
            "\tTrain Loss: 0.796 | Train Acc: 75.53%\n",
            "\tTrain Loss: 0.768 | Train Acc: 77.78%\n",
            "\tTrain Loss: 0.738 | Train Acc: 81.54%\n",
            "\tTrain Loss: 0.716 | Train Acc: 84.15%\n",
            "\tTrain Loss: 0.704 | Train Acc: 84.72%\n",
            "\tTrain Loss: 0.699 | Train Acc: 84.86%\n",
            "\tTrain Loss: 0.695 | Train Acc: 85.01%\n",
            "\tTrain Loss: 0.663 | Train Acc: 89.68%\n",
            "\tTrain Loss: 0.618 | Train Acc: 94.46%\n",
            "\tTrain Loss: 0.595 | Train Acc: 96.50%\n",
            "\tTrain Loss: 0.583 | Train Acc: 97.94%\n",
            "\tTrain Loss: 0.577 | Train Acc: 98.66%\n",
            "\tTrain Loss: 0.572 | Train Acc: 98.89%\n",
            "\tTrain Loss: 0.573 | Train Acc: 98.65%\n",
            "\tTrain Loss: 0.567 | Train Acc: 99.01%\n",
            "\tTrain Loss: 0.569 | Train Acc: 98.76%\n",
            "\tTrain Loss: 0.564 | Train Acc: 99.16%\n",
            "\tTrain Loss: 0.563 | Train Acc: 99.11%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjECAgG4XWzL"
      },
      "source": [
        "torch.save(model.state_dict(), 'saved_weights.pt')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2AUBu-88QP9",
        "outputId": "8acb6a0d-da84-4d15-fb17-396d1b7524c4"
      },
      "source": [
        "model.load_state_dict(torch.load('saved_weights.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.680 | Test Acc: 86.79%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R6Qj9eJ8UWd"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_sentence(texts):\n",
        "    \n",
        "    categories = {0: \"Very Negative\", 1:\"Negative\", 2:\"Neutral\", 3:\"Positive\", 4:\"Very Positive\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(texts)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQN9AbRdqclI"
      },
      "source": [
        "User Input Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t8OHs_1P8bOP",
        "outputId": "bf26c381-815d-4bf7-a83a-b156210c6620"
      },
      "source": [
        "classify_sentence(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Neutral'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WuIkgkW48grs",
        "outputId": "03e4662f-bf72-44e0-e5eb-33a8d120e76a"
      },
      "source": [
        "classify_sentence(\"In his teen years, Obama has been known to use marijuana and cocaine.\")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7a5h75SdXerP",
        "outputId": "7742ba6e-adb0-434b-b637-ac5e22bab4d8"
      },
      "source": [
        "classify_sentence(\"A masterpiece four years in the making.\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UlEVeQLYY15M",
        "outputId": "018b5db1-87e0-4553-a89c-fcd9a4aa6d50"
      },
      "source": [
        "classify_sentence(\"The movie 's ripe , enrapturing beauty will tempt those willing to probe its inscrutable mysteries.\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    }
  ]
}